{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Probabilistic Product of Exponentials\n\nWe compute the probabilistic forward kinematics of a robot with flexible\nlinks or joints and visualize the projected equiprobably ellipsoid of the\nend-effector's pose distribution.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os\nimport numpy as np\nfrom matplotlib import cbook\nimport open3d as o3d\nfrom pytransform3d.urdf import UrdfTransformManager\nimport pytransform3d.transformations as pt\nimport pytransform3d.trajectories as ptr\nimport pytransform3d.uncertainty as pu\nimport pytransform3d.visualizer as pv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Probabilistic Robot Kinematics\n\nThe end-effector's pose distribution is computed based on the Probabilistic\nProduct of Exponentials PPOE [1]_.\n\nOur ProbabilisticRobotKinematics class is a subclass of\n:class:`~pytransform3d.urdf.UrdfTransformManager`, which loads a description\nof a robot from the URDF format.\n\nThe complicated part of this example is the conversion of kinematics\nparameters from URDF data to screw axes that are needed for the product\nof exponentials formulation of forward kinematics.\n\nOnce we have this information, the implementation of the probabilistic\nproduct of exponentials is straightforward:\n\n1. We multiply the screw axis of each joint with the corresponding joint\n   angle to obtain the exponential coordinates of each relative joint\n   displacement.\n2. We concatenate the relative joint displacements and the base pose to\n   obtain the end-effector's pose. This is the original product of\n   exponentials.\n3. The PPOE modifies the original product of exponentials by transforming\n   and concatenating the covariances of each transformation.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class ProbabilisticRobotKinematics(UrdfTransformManager):\n    \"\"\"Probabilistic robot kinematics.\n\n    Parameters\n    ----------\n    robot_urdf : str\n        URDF description of robot\n\n    ee_frame : str\n        Name of the end-effector frame\n\n    base_frame : str\n        Name of the base frame\n\n    joint_names : list\n        Names of joints in order from base to end effector\n\n    mesh_path : str, optional (default: None)\n        Path in which we search for meshes that are defined in the URDF.\n        Meshes will be ignored if it is set to None and no 'package_dir'\n        is given.\n\n    package_dir : str, optional (default: None)\n        Some URDFs start file names with 'package://' to refer to the ROS\n        package in which these files (textures, meshes) are located. This\n        variable defines to which path this prefix will be resolved.\n    \"\"\"\n    def __init__(self, robot_urdf, ee_frame, base_frame, joint_names,\n                 mesh_path=None, package_dir=None):\n        super(ProbabilisticRobotKinematics, self).__init__(check=False)\n        self.load_urdf(robot_urdf, mesh_path=mesh_path,\n                       package_dir=package_dir)\n        self.ee2base_home, self.screw_axes_home = \\\n            self._get_screw_axes(ee_frame, base_frame, joint_names)\n        self.joint_limits = np.array([\n            self.get_joint_limits(jn) for jn in joint_names])\n\n    def _get_screw_axes(self, ee_frame, base_frame, joint_names):\n        \"\"\"Get screw axes of joints in space frame at robot's home position.\n\n        Parameters\n        ----------\n        ee_frame : str\n            Name of the end-effector frame\n\n        base_frame : str\n            Name of the base frame\n\n        joint_names : list\n            Names of joints in order from base to end effector\n\n        Returns\n        -------\n        ee2base_home : array, shape (4, 4)\n            The home configuration (position and orientation) of the\n            end-effector.\n\n        screw_axes_home : array, shape (n_joints, 6)\n            The joint screw axes in the space frame when the manipulator is at\n            the home position.\n        \"\"\"\n        ee2base_home = self.get_transform(ee_frame, base_frame)\n        screw_axes_home = []\n        for jn in joint_names:\n            ln, _, _, s_axis, limits, joint_type = self._joints[jn]\n            link2base = self.get_transform(ln, base_frame)\n            s_axis = np.dot(link2base[:3, :3], s_axis)\n            q = link2base[:3, 3]\n\n            if joint_type == \"revolute\":\n                h = 0.0\n            elif joint_type == \"prismatic\":\n                h = np.inf\n            else:\n                raise NotImplementedError(\n                    \"Joint type %s not supported.\" % joint_type)\n\n            screw_axis = pt.screw_axis_from_screw_parameters(q, s_axis, h)\n            screw_axes_home.append(screw_axis)\n        screw_axes_home = np.row_stack(screw_axes_home)\n        return ee2base_home, screw_axes_home\n\n    def probabilistic_forward_kinematics(self, thetas, covs):\n        \"\"\"Compute probabilistic forward kinematics.\n\n        This is based on the probabilistic product of exponentials.\n\n        Parameters\n        ----------\n        thetas : array, shape (n_joints,)\n            A list of joint coordinates.\n\n        covs : array, shape (n_joints, 6, 6)\n            Covariances of joint transformations.\n\n        Returns\n        -------\n        ee2base : array, shape (4, 4)\n            A homogeneous transformation matrix representing the end-effector\n            frame when the joints are at the specified coordinates.\n\n        cov : array, shape (6, 6)\n            Covariance of the pose in tangent space.\n        \"\"\"\n        assert len(thetas) == self.screw_axes_home.shape[0]\n        thetas = np.clip(\n            thetas, self.joint_limits[:, 0], self.joint_limits[:, 1])\n\n        Sthetas = self.screw_axes_home * thetas[:, np.newaxis]\n        joint_displacements = ptr.transforms_from_exponential_coordinates(\n            Sthetas)\n\n        T = np.eye(4)\n        cov = np.zeros((6, 6))\n        for i in range(len(thetas)):\n            T, cov = pu.concat_locally_uncertain_transforms(\n                joint_displacements[i], T, covs[i], cov)\n\n        T = T.dot(self.ee2base_home)\n        ad = pt.adjoint_from_transform(self.ee2base_home)\n        cov = ad.dot(cov).dot(ad.T)\n\n        return T, cov"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Mesh Visualization\nTo visualize the 6D covariance in the tangent space of SE(3), we project its\nequiprobable hyper-ellipsoid to 3D and represent it as a mesh. We can then\nvisualize the mesh with this class.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class Surface(pv.Artist):\n    \"\"\"Surface to be visualized with Open3D.\n\n    Parameters\n    ----------\n    x : array, shape (n_steps, n_steps)\n        Coordinates on x-axis of grid on surface.\n\n    y : array, shape (n_steps, n_steps)\n        Coordinates on y-axis of grid on surface.\n\n    z : array, shape (n_steps, n_steps)\n        Coordinates on z-axis of grid on surface.\n\n    c : array-like, shape (3,), optional (default: None)\n        Color\n    \"\"\"\n    def __init__(self, x, y, z, c=None):\n        self.c = c\n        self.mesh = o3d.geometry.TriangleMesh()\n        self.set_data(x, y, z)\n\n    def set_data(self, x, y, z):\n        \"\"\"Update data.\n\n        Parameters\n        ----------\n        x : array, shape (n_steps, n_steps)\n            Coordinates on x-axis of grid on surface.\n\n        y : array, shape (n_steps, n_steps)\n            Coordinates on y-axis of grid on surface.\n\n        z : array, shape (n_steps, n_steps)\n            Coordinates on z-axis of grid on surface.\n        \"\"\"\n        polys = np.stack([cbook._array_patch_perimeters(a, 1, 1)\n                          for a in (x, y, z)], axis=-1)\n        vertices = polys.reshape(-1, 3)\n        triangles = (\n            [[4 * i + 0, 4 * i + 1, 4 * i + 2] for i in range(len(polys))] +\n            [[4 * i + 2, 4 * i + 3, 4 * i + 0] for i in range(len(polys))] +\n            [[4 * i + 0, 4 * i + 3, 4 * i + 2] for i in range(len(polys))] +\n            [[4 * i + 2, 4 * i + 1, 4 * i + 0] for i in range(len(polys))]\n        )\n        self.mesh.vertices = o3d.utility.Vector3dVector(vertices)\n        self.mesh.triangles = o3d.utility.Vector3iVector(triangles)\n        if self.c is not None:\n            self.mesh.paint_uniform_color(self.c)\n        self.mesh.compute_vertex_normals()\n\n    @property\n    def geometries(self):\n        \"\"\"Expose geometries.\n\n        Returns\n        -------\n        geometries : list\n            List of geometries that can be added to the visualizer.\n        \"\"\"\n        return [self.mesh]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then we define a callback to animate the visualization.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def animation_callback(\n        step, n_frames, tm, graph, joint_names, thetas, covs, surface):\n    angle = 0.5 * np.cos(2.0 * np.pi * (0.5 + step / n_frames))\n    thetas_t = angle * thetas\n    for joint_name, value in zip(joint_names, thetas_t):\n        tm.set_joint(joint_name, value)\n    graph.set_data()\n\n    T, cov = tm.probabilistic_forward_kinematics(thetas_t, covs)\n    x, y, z = pu.to_projected_ellipsoid(T, cov, factor=1, n_steps=50)\n    surface.set_data(x, y, z)\n\n    return graph, surface"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\nWe load the URDF file,\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "BASE_DIR = \"test/test_data/\"\ndata_dir = BASE_DIR\nsearch_path = \".\"\nwhile (not os.path.exists(data_dir) and\n       os.path.dirname(search_path) != \"pytransform3d\"):\n    search_path = os.path.join(search_path, \"..\")\n    data_dir = os.path.join(search_path, BASE_DIR)\nfilename = os.path.join(data_dir, \"robot_with_visuals.urdf\")\nwith open(filename, \"r\") as f:\n    robot_urdf = f.read()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "define the kinematic chain that we are interested in,\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "joint_names = [\"joint%d\" % i for i in range(1, 7)]\ntm = ProbabilisticRobotKinematics(\n    robot_urdf, \"tcp\", \"linkmount\", joint_names, mesh_path=data_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "define the joint angles,\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "thetas = np.array([1, 1, 1, 0, 1, 0])\ncurrent_thetas = -0.5 * thetas\nfor joint_name, theta in zip(joint_names, current_thetas):\n    tm.set_joint(joint_name, theta)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "and define the covariances of the joints.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "covs = np.zeros((len(thetas), 6, 6))\ncovs[0] = np.diag([0, 0, 1, 0, 0, 0])\ncovs[1] = np.diag([0, 1, 0, 0, 0, 0])\ncovs[2] = np.diag([0, 1, 0, 0, 0, 0])\ncovs[4] = np.diag([0, 1, 0, 0, 0, 0])\ncovs *= 0.05"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## PPOE and Visualization\n\nThen we can finally use PPOE to compute the end-effector pose and its\ncovariance.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "T, cov = tm.probabilistic_forward_kinematics(current_thetas, covs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We compute the 3D projection of the 6D covariance matrix.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "x, y, z = pu.to_projected_ellipsoid(T, cov, factor=1, n_steps=50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The following code visualizes the result.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig = pv.figure()\ngraph = fig.plot_graph(tm, \"robot_arm\", show_visuals=True)\nfig.plot_transform(np.eye(4), s=0.3)\nsurface = Surface(x, y, z, c=(0, 0.5, 0.5))\nsurface.add_artist(fig)\nfig.view_init(elev=5, azim=50)\nn_frames = 200\nif \"__file__\" in globals():\n    fig.animate(animation_callback, n_frames, loop=True,\n                fargs=(n_frames, tm, graph, joint_names, thetas, covs,\n                       surface))\n    fig.show()\nelse:\n    fig.save_image(\"__open3d_rendered_image.jpg\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## References\n\n.. [1] Meyer, Strobl, Triebel (2022): The Probabilistic Robot Kinematics\n   Model and its Application to Sensor Fusion. In IEEE/RSJ International\n   Conference on Intelligent Robots and Systems (IROS), Kyoto, Japan, 2022,\n   pp. 3263-3270, doi: 10.1109/IROS47612.2022.9981399.\n   https://elib.dlr.de/191928/1/202212_ELIB_PAPER_VERSION_with_copyright.pdf\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}